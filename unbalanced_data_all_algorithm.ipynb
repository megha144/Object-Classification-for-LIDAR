{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, roc_auc_score,precision_recall_curve\n",
    "from sklearn.model_selection import StratifiedKFold, ShuffleSplit\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize,LabelEncoder, MinMaxScaler\n",
    "from scipy import interp\n",
    "import matplotlib.patches as patches\n",
    "import csv\n",
    "from numpy import array, argmax\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_log_error,log_loss, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, learning_curve, validation_curve\n",
    "from sklearn.svm import SVC\n",
    "import yellowbrick as yb\n",
    "from yellowbrick.features import Rank1D, PCADecomposition\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "from sklearn.feature_selection import RFECV\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import matplotlib.patches as mpatches\n",
    "from yellowbrick.target import FeatureCorrelation\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import hamming_loss\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = pd.read_csv('/home/lddev002/Jupyter_notebooks_innovusion/innovusion_features_updated/final_feature/innovusion_features_all_new.txt',delimiter=\"\\t\",error_bad_lines=False,header=None,\n",
    "                  names=['class','height','width','box_volume','l1','l2','l3','eigen_curvature','eigen_entropy','omnivariance','anisotropy','sum_eigen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Car', 'Cyclist', 'Misc', 'Motorbike', 'Pedestrian']\n"
     ]
    }
   ],
   "source": [
    "#Integer Encoding\n",
    "# integer encode class labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_updated['class'])\n",
    "print(list(le.classes_))\n",
    "integer_encoded = le.transform(df_updated['class']) \n",
    "\n",
    "#integer_encoded = label_encoder.fit_transform(df_shuffled['class'])\n",
    "\n",
    "df_shuffled_part1 = df_updated[['height','width','box_volume','l1','l2','l3','eigen_curvature','eigen_entropy','omnivariance','anisotropy','sum_eigen']]\n",
    "\n",
    "integer_encoded_class = pd.DataFrame(integer_encoded)\n",
    "\n",
    "\n",
    "#final shuffled dataframe with  integer encoded class labels\n",
    "df_encoded = integer_encoded_class.join(df_shuffled_part1)\n",
    "\n",
    "df_encoded.columns.values[0] = 'class'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle df_balanced\n",
    "df_encoded = df_encoded.reindex(np.random.permutation(df_encoded.index))\n",
    "df_encoded.index = range(df_encoded.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicates and Reindex rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df_encoded.drop_duplicates()\n",
    "df_encoded.index = range(df_encoded.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded[['class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Total class samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Outlier removal\n",
      "----------------------------\n",
      "Total : 1387 | Car : 825 | Pedestrian : 184 | Cyclist : 182 | Motorbike : 196 \n"
     ]
    }
   ],
   "source": [
    "# Total samples\n",
    "# filter different class samples\n",
    "\n",
    "df_car_filter = df_encoded['class']==0\n",
    "df_pedestrian_filter = df_encoded['class']==4\n",
    "df_cyclist_filter = df_encoded['class']==1\n",
    "df_misc_filter = df_encoded['class']==2\n",
    "df_motorbike_filter = df_encoded['class']==3\n",
    "\n",
    "\n",
    "# create sub dataframe for each filtered class\n",
    "\n",
    "df_car = df_encoded[df_car_filter]\n",
    "df_pedestrian = df_encoded[df_pedestrian_filter]\n",
    "df_cyclist = df_encoded[df_cyclist_filter]\n",
    "df_motorbike = df_encoded[df_motorbike_filter]\n",
    "df_misc = df_encoded[df_misc_filter]\n",
    "\n",
    "print(\"Before Outlier removal\")\n",
    "print(\"----------------------------\")\n",
    "print(\"Total : {} | Car : {} | Pedestrian : {} | Cyclist : {} | Motorbike : {} \".format(df_encoded.shape[0] - df_misc.shape[0], df_car.shape[0],df_pedestrian.shape[0],df_cyclist.shape[0],df_motorbike.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier removal from data distribution (Class wise each feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal - Class - Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f107028e810>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_car_h = df_car[(df_car['height'] >=0) & (df_car['height'] <= 2.5)]\n",
    "df_car_w = df_car[(df_car['width'] >=0.7) & (df_car['width'] <= 2.0)]\n",
    "df_car_v = df_car[(df_car['box_volume'] >=0.0) & (df_car['box_volume'] <= 6.0)]\n",
    "df_car_l1 = df_car[(df_car['l1'] >=0.5) & (df_car['l1'] <= 40.0)]\n",
    "df_car_l2 = df_car[(df_car['l2'] >=0.5) & (df_car['l2'] <= 20.0)]\n",
    "df_car_l3 = df_car[(df_car['l3'] >=0.5) & (df_car['l3'] <= 14.0)]\n",
    "df_car_eigen_curve = df_car[(df_car['eigen_curvature'] >=0.02) & (df_car['eigen_curvature'] <= 0.15)]\n",
    "df_car_eigen_entropy = df_car[(df_car['eigen_entropy'] >=0.6) & (df_car['eigen_entropy'] <= 1.0)]\n",
    "df_car_omnivariance = df_car[(df_car['omnivariance'] >=0.15) & (df_car['omnivariance'] <= 0.30)]\n",
    "df_car_anisotropy = df_car[(df_car['anisotropy'] >=0.75) & (df_car['anisotropy'] <= 1.0)]\n",
    "df_car_sum_eigen = df_car[(df_car['sum_eigen'] >=0.0) & (df_car['sum_eigen'] <= 70.0)]\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.distplot(df_car_h['height'])\n",
    "sns.distplot(df_car_w['width'])\n",
    "sns.distplot(df_car_v['box_volume'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_car_without_noise = pd.concat([df_car_h['height'], df_car_w['width'],df_car_v['box_volume'],\n",
    "                             df_car_l1['l1'],df_car_l2['l2'],df_car_l3['l3'],\n",
    "                             df_car_eigen_curve['eigen_curvature'],\n",
    "                             df_car_eigen_entropy['eigen_entropy'],\n",
    "                             df_car_omnivariance['omnivariance'],\n",
    "                             df_car_anisotropy['anisotropy'],\n",
    "                             df_car_sum_eigen['sum_eigen']],1)\n",
    "df_car_without_noise.dropna(inplace= True)\n",
    "df_car_without_noise.insert(0, \"class\", 0, True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Outlier Removal - Class - Cyclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclist_h = df_cyclist[(df_cyclist['height'] >=0.5) & (df_cyclist['height'] <= 2.2)]\n",
    "df_cyclist_w = df_cyclist[(df_cyclist['width'] >=0.45) & (df_cyclist['width'] <= 0.8)]\n",
    "df_cyclist_v = df_cyclist[(df_cyclist['box_volume'] >=0.2) & (df_cyclist['box_volume'] <= 3.0)]\n",
    "df_cyclist_l1 = df_cyclist[(df_cyclist['l1'] >=0.5) & (df_cyclist['l1'] <= 100.0)]\n",
    "df_cyclist_l2 = df_cyclist[(df_cyclist['l2'] >=0.5) & (df_cyclist['l2'] <= 50.0)]\n",
    "df_cyclist_l3 = df_cyclist[(df_cyclist['l3'] >=0.5) & (df_cyclist['l3'] <= 35.0)]\n",
    "df_cyclist_eigen_curve = df_cyclist[(df_cyclist['eigen_curvature'] >=0.01) & (df_cyclist['eigen_curvature'] <= 0.09)]\n",
    "df_cyclist_eigen_entropy = df_cyclist[(df_cyclist['eigen_entropy'] >=0.5) & (df_cyclist['eigen_entropy'] <= 0.9)]\n",
    "df_cyclist_omnivariance = df_cyclist[(df_cyclist['omnivariance'] >=0.150) & (df_cyclist['omnivariance'] <= 0.235)]\n",
    "df_cyclist_anisotropy = df_cyclist[(df_cyclist['anisotropy'] >=0.85) & (df_cyclist['anisotropy'] <= 1.0)]\n",
    "df_cyclist_sum_eigen = df_cyclist[(df_cyclist['sum_eigen'] >=0.0) & (df_cyclist['sum_eigen'] <= 130.0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cyclist_without_noise = pd.concat([df_cyclist_h['height'], df_cyclist_w['width'],df_cyclist_v['box_volume'],\n",
    "                             df_cyclist_l1['l1'],df_cyclist_l2['l2'],df_cyclist_l3['l3'],\n",
    "                             df_cyclist_eigen_curve['eigen_curvature'],\n",
    "                             df_cyclist_eigen_entropy['eigen_entropy'],\n",
    "                             df_cyclist_omnivariance['omnivariance'],\n",
    "                             df_cyclist_anisotropy['anisotropy'],\n",
    "                             df_cyclist_sum_eigen['sum_eigen']],1)\n",
    "df_cyclist_without_noise.dropna(inplace= True)\n",
    "df_cyclist_without_noise.insert(0, \"class\", 1, True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal - Class - Motorbike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_motorbike_h = df_motorbike[(df_motorbike['height'] >=1.2) & (df_motorbike['height'] <= 2.0)]\n",
    "df_motorbike_w = df_motorbike[(df_motorbike['width'] >=0.65) & (df_motorbike['width'] <= 0.9)]\n",
    "df_motorbike_v = df_motorbike[(df_motorbike['box_volume'] >=1.1) & (df_motorbike['box_volume'] <= 2.3)]\n",
    "df_motorbike_l1 = df_motorbike[(df_motorbike['l1'] >=12) & (df_motorbike['l1'] <= 35.0)]\n",
    "df_motorbike_l2 = df_motorbike[(df_motorbike['l2'] >=4) & (df_motorbike['l2'] <= 15.0)]\n",
    "df_motorbike_l3 = df_motorbike[(df_motorbike['l3'] >=0.2) & (df_motorbike['l3'] <= 15.0)]\n",
    "df_motorbike_eigen_curve = df_motorbike[(df_motorbike['eigen_curvature'] >=0.075) & (df_motorbike['eigen_curvature'] <= 0.150)]\n",
    "df_motorbike_eigen_entropy = df_motorbike[(df_motorbike['eigen_entropy'] >=0.85) & (df_motorbike['eigen_entropy'] <= 0.97)]\n",
    "df_motorbike_omnivariance = df_motorbike[(df_motorbike['omnivariance'] >=0.25) & (df_motorbike['omnivariance'] <= 0.30)]\n",
    "df_motorbike_anisotropy = df_motorbike[(df_motorbike['anisotropy'] >=0.75) & (df_motorbike['anisotropy'] <= 0.87)]\n",
    "df_motorbike_sum_eigen = df_motorbike[(df_motorbike['sum_eigen'] >=20) & (df_motorbike['sum_eigen'] <= 65.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_motorbike_without_noise = pd.concat([df_motorbike_h['height'], df_motorbike_w['width'],df_motorbike_v['box_volume'],\n",
    "                             df_motorbike_l1['l1'],df_motorbike_l2['l2'],df_motorbike_l3['l3'],\n",
    "                             df_motorbike_eigen_curve['eigen_curvature'],\n",
    "                             df_motorbike_eigen_entropy['eigen_entropy'],\n",
    "                             df_motorbike_omnivariance['omnivariance'],\n",
    "                             df_motorbike_anisotropy['anisotropy'],\n",
    "                             df_motorbike_sum_eigen['sum_eigen']],1)\n",
    "df_motorbike_without_noise.dropna(inplace= True)\n",
    "df_motorbike_without_noise.insert(0, \"class\", 3, True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal - Class - Pedestrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pedestrian_h = df_pedestrian[(df_pedestrian['height'] >=0.4) & (df_pedestrian['height'] <= 2.0)]\n",
    "df_pedestrian_w = df_pedestrian[(df_pedestrian['width'] >=0.2) & (df_pedestrian['width'] <= 1.25)]\n",
    "df_pedestrian_v = df_pedestrian[(df_pedestrian['box_volume'] >=0.0) & (df_pedestrian['box_volume'] <= 3.0)]\n",
    "df_pedestrian_l1 = df_pedestrian[(df_pedestrian['l1'] >=0) & (df_pedestrian['l1'] <= 50.0)]\n",
    "df_pedestrian_l2 = df_pedestrian[(df_pedestrian['l2'] >=0) & (df_pedestrian['l2'] <= 40.0)]\n",
    "df_pedestrian_l3 = df_pedestrian[(df_pedestrian['l3'] >=0) & (df_pedestrian['l3'] <= 25.0)]\n",
    "df_pedestrian_eigen_curve = df_pedestrian[(df_pedestrian['eigen_curvature'] >=0.000) & (df_pedestrian['eigen_curvature'] <= 0.100)]\n",
    "df_pedestrian_eigen_entropy = df_pedestrian[(df_pedestrian['eigen_entropy'] >=0.2) & (df_pedestrian['eigen_entropy'] <=1.00)]\n",
    "df_pedestrian_omnivariance = df_pedestrian[(df_pedestrian['omnivariance'] >=0.05) & (df_pedestrian['omnivariance'] <= 0.30)]\n",
    "df_pedestrian_anisotropy = df_pedestrian[(df_pedestrian['anisotropy'] >=0.85) & (df_pedestrian['anisotropy'] <= 1.00)]\n",
    "df_pedestrian_sum_eigen = df_pedestrian[(df_pedestrian['sum_eigen'] >=4) & (df_pedestrian['sum_eigen'] <= 80.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pedestrian_without_noise = pd.concat([df_pedestrian_h['height'], df_pedestrian_w['width'],df_pedestrian_v['box_volume'],\n",
    "                             df_pedestrian_l1['l1'],df_pedestrian_l2['l2'],df_pedestrian_l3['l3'],\n",
    "                             df_pedestrian_eigen_curve['eigen_curvature'],\n",
    "                             df_pedestrian_eigen_entropy['eigen_entropy'],\n",
    "                             df_pedestrian_omnivariance['omnivariance'],\n",
    "                             df_pedestrian_anisotropy['anisotropy'],\n",
    "                             df_pedestrian_sum_eigen['sum_eigen']],1)\n",
    "df_pedestrian_without_noise.dropna(inplace= True)\n",
    "df_pedestrian_without_noise.insert(0, \"class\", 4, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join each Class wise features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = df_car_without_noise.append(df_cyclist_without_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result1.append(df_motorbike_without_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = result2.append(df_pedestrian_without_noise) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Outlier removal\n",
      "----------------------------\n",
      "Total : 764 | Car : 448 | Pedestrian : 134 | Cyclist : 74 | Motorbike : 108 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"After Outlier removal\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "\n",
    "print(\"Total : {} | Car : {} | Pedestrian : {} | Cyclist : {} | Motorbike : {} \".format(result3.shape[0], df_car_without_noise.shape[0],df_pedestrian_without_noise.shape[0],df_cyclist_without_noise.shape[0],df_motorbike_without_noise.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before outlier removal (without misc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_condition = df_encoded['class'] != 2\n",
    "df_encoded_no_misc = df_encoded[df_encoded_condition]\n",
    "df_encoded_no_misc.index = range(df_encoded_no_misc.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 12)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total samples\n",
    "# filter different class samples\n",
    "\n",
    "car_filter = result3['class']==0\n",
    "pedestrian_filter = result3['class']==4\n",
    "cyclist_filter = result3['class']==1\n",
    "motorbike_filter = result3['class']==3\n",
    "\n",
    "\n",
    "# create sub dataframe for each filtered class\n",
    "\n",
    "car = result3[car_filter]\n",
    "pedestrian = result3[pedestrian_filter]\n",
    "cyclist = result3[cyclist_filter]\n",
    "motorbike = result3[motorbike_filter]\n",
    "\n",
    "\n",
    "car.index = range(car.shape[0])\n",
    "pedestrian.index = range(pedestrian.shape[0])\n",
    "cyclist.index = range(cyclist.shape[0])\n",
    "motorbike.index = range(motorbike.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "#take equal samples\n",
    "\n",
    "\n",
    "#car - 180 samples\n",
    "rows1 = np.random.choice(car.index.values, 74)\n",
    "df_car_74 = car.loc[rows1]\n",
    "\n",
    "\n",
    "#pedestrian - 180 samples\n",
    "rows2 = np.random.choice(pedestrian.index.values,74)\n",
    "df_pedestrian_74 = pedestrian.loc[rows2]\n",
    "\n",
    "\n",
    "#cyclist - 180 samples\n",
    "rows3 = np.random.choice(cyclist.index.values,74)\n",
    "df_cyclist_74 = cyclist.loc[rows3]\n",
    "\n",
    "\n",
    "#motorbike - 180 samples\n",
    "rows4 = np.random.choice(motorbike.index.values,74)\n",
    "df_motorbike_74 = motorbike.loc[rows4]\n",
    "\n",
    "\n",
    "\n",
    "result3_new = pd.concat([df_car_74,df_cyclist_74,df_motorbike_74,df_pedestrian_74],axis = 0)\n",
    "#shuffle df_balanced\n",
    "result3_new.index = range(result3_new.shape[0])\n",
    "\n",
    "#shuffle df_balanced\n",
    "result3_new = result3_new.reindex(np.random.permutation(result3_new.index))\n",
    "result3_new.index = range(result3_new.shape[0])\n",
    "\n",
    "result3_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Features per each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "#catplot\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "sns.catplot(x=\"class\", y=\"height\", data=result3)\n",
    "\n",
    "sns.catplot(x=\"class\", y=\"width\", data=result3)\n",
    "\n",
    "sns.catplot(x=\"class\", y=\"box_volume\", data=result3)\n",
    "\n",
    "sns.catplot(x=\"class\", y=\"l1\", data=result3)\n",
    "\n",
    "sns.catplot(x=\"class\", y=\"l2\", data=result3)\n",
    "\n",
    "sns.catplot(x=\"class\", y=\"l3\", data=result3)\n",
    "\n",
    "sns.catplot(x=\"class\", y=\"eigen_curvature\", data=result3)\n",
    "sns.catplot(x=\"class\", y=\"eigen_entropy\", data=result3)\n",
    "sns.catplot(x=\"class\", y=\"omnivariance\", data=result3)\n",
    "sns.catplot(x=\"class\", y=\"anisotropy\", data=result3)\n",
    "sns.catplot(x=\"class\", y=\"sum_eigen\", data=result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Feature Scaling - Divide X-Features and Y-Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = ['height','width','box_volume']\n",
    "eigen_features = ['l1','l2','l3','eigen_curvature','eigen_entropy','omnivariance','anisotropy','sum_eigen']\n",
    "all_features = ['height','width','box_volume','l1','l2','l3','eigen_curvature','eigen_entropy','omnivariance','anisotropy','sum_eigen']\n",
    "\n",
    "\n",
    "# new normalization\n",
    "scaler_h = preprocessing.StandardScaler().fit(result3[['height']])\n",
    "scaler_w = preprocessing.StandardScaler().fit(result3[['width']])\n",
    "scaler_v = preprocessing.StandardScaler().fit(result3[['box_volume']])\n",
    "scaler_l1 = preprocessing.StandardScaler().fit(result3[['l1']])\n",
    "scaler_l2 = preprocessing.StandardScaler().fit(result3[['l2']])\n",
    "scaler_l3 = preprocessing.StandardScaler().fit(result3[['l3']])\n",
    "scaler_eigen_curve = preprocessing.StandardScaler().fit(result3[['eigen_curvature']])\n",
    "scaler_eigen_entropy = preprocessing.StandardScaler().fit(result3[['eigen_entropy']])\n",
    "scaler_omnivariance = preprocessing.StandardScaler().fit(result3[['omnivariance']])\n",
    "scaler_anisotropy = preprocessing.StandardScaler().fit(result3[['anisotropy']])\n",
    "scaler_sum_eigen = preprocessing.StandardScaler().fit(result3[['sum_eigen']])\n",
    "\n",
    "scaled_df_h = scaler_h.transform(result3[['height']])\n",
    "scaled_df_w = scaler_w.transform(result3[['width']])\n",
    "scaled_df_v = scaler_v.transform(result3[['box_volume']])\n",
    "scaled_df_l1 = scaler_l1.transform(result3[['l1']])\n",
    "scaled_df_l2 = scaler_l2.transform(result3[['l2']])\n",
    "scaled_df_l3 = scaler_l3.transform(result3[['l3']])\n",
    "scaled_df_eigen_curve = scaler_eigen_curve.transform(result3[['eigen_curvature']])\n",
    "scaled_df_eigen_entropy = scaler_eigen_entropy.transform(result3[['eigen_entropy']])\n",
    "scaled_df_omnivariance = scaler_omnivariance.transform(result3[['omnivariance']])\n",
    "scaled_df_anisotropy = scaler_anisotropy.transform(result3[['anisotropy']])\n",
    "scaled_df_sum_eigen = scaler_sum_eigen.transform(result3[['sum_eigen']])\n",
    "\n",
    "simple_scaled = [scaled_df_h, scaled_df_w, scaled_df_v]\n",
    "eigen_scaled = [scaled_df_l1,scaled_df_l2,scaled_df_l3,scaled_df_eigen_curve,scaled_df_eigen_entropy,scaled_df_omnivariance,scaled_df_anisotropy,scaled_df_sum_eigen]\n",
    "all_scaled = [scaled_df_h, scaled_df_w, scaled_df_v,scaled_df_l1,scaled_df_l2,scaled_df_l3,scaled_df_eigen_curve,scaled_df_eigen_entropy,scaled_df_omnivariance,scaled_df_anisotropy,scaled_df_sum_eigen]\n",
    "\n",
    "\n",
    "scaled_df = np.column_stack(all_scaled)\n",
    "scaled_df_new = pd.DataFrame(scaled_df,columns = all_features)\n",
    "\n",
    "\n",
    "X = np.array(scaled_df_new[all_features])\n",
    "Y = np.array(result3[['class']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Feature Scaling - Divide X-Features and Y-Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = ['height','width','box_volume']\n",
    "eigen_features = ['l1','l2','l3','eigen_curvature','eigen_entropy','omnivariance','anisotropy','sum_eigen']\n",
    "all_features = ['height','width','box_volume','l1','l2','l3','eigen_curvature','eigen_entropy','omnivariance','anisotropy','sum_eigen']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = np.array(result3_new[all_features])\n",
    "Y = np.array(result3_new[['class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Parameter search - Random Forest (RandomSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 'warn',\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  5.8min finished\n",
      "/home/lddev002/.local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lddev002/.local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 1600}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BEST PARAMETER SEARCH\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "#pprint(random_grid)\n",
    "\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, \n",
    "                               cv =KFold(10, shuffle=False,random_state = 42), verbose=3, \n",
    "                               random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X, Y)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Parameter search - SVM (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  1.4min finished\n",
      "/home/lddev002/.local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lddev002/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best score for our data:', 0.9628378378378378)\n",
      "('Best C:', 1000)\n",
      "('Best Kernel:', 'linear')\n",
      "('Best Gamma:', 'auto_deprecated')\n"
     ]
    }
   ],
   "source": [
    "#Best Parameter Search\n",
    "\n",
    "#feature scaling\n",
    "\n",
    "parameter_candidates = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                     'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]},\n",
    "                    {'kernel': ['sigmoid'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                     'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]}\n",
    "                   ]\n",
    "\n",
    "# Create a classifier object with the classifier and parameter candidates\n",
    "clf2 = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1,\n",
    "                    cv=KFold(10, shuffle=False,random_state = 42),verbose = 3)\n",
    "\n",
    "# Train the classifier on data1's feature and target data\n",
    "clf2.fit(X, Y)   \n",
    "\n",
    "# View the accuracy score\n",
    "print('Best score for our data:', clf2.best_score_) \n",
    "\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',clf2.best_estimator_.C) \n",
    "print('Best Kernel:',clf2.best_estimator_.kernel)\n",
    "print('Best Gamma:',clf2.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Parameter search - KNN(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 192 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   53.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best Hyper Parameters:\\n', {'n_neighbors': 9, 'n_jobs': -1, 'weights': 'distance', 'leaf_size': 1, 'algorithm': 'auto'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed:  1.1min finished\n",
      "/home/lddev002/.local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lddev002/.local/lib/python2.7/site-packages/sklearn/model_selection/_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "#BEST PARAMETER SEARCH\n",
    "\n",
    "#making the instance\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "#Hyper Parameters Set\n",
    "params = {'n_neighbors':[5,6,7,8,9,10],\n",
    "          'leaf_size':[1,2,3,5],\n",
    "          'weights':['uniform', 'distance'],\n",
    "          'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
    "          'n_jobs':[-1]}\n",
    "\n",
    "#Making models with hyper parameters sets\n",
    "model1 = GridSearchCV(model, param_grid=params, n_jobs=-1,cv=KFold(10,random_state = 42, shuffle=False),verbose = 3)\n",
    "\n",
    "#Learning\n",
    "model1.fit(X,Y)\n",
    "\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\\n\",model1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Fold  (10 Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lddev002/.local/lib/python2.7/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean error', 3.1637182431047747e-15)\n",
      "('classifier score : ', 0.8666666666666667)\n",
      "For k =  0 | train set size : 266 | test set size : 30\n",
      "------------------ for k : 0---------------------\n",
      "('classification error : ', 0.1333333333333333)\n",
      "('precision score : ', 0.8833333333333334)\n",
      "('Recall : ', 0.8666666666666667)\n",
      "('F1 score : ', 0.8660884866767219)\n",
      "('Mean Absolute Error : ', 0.36666666666666664)\n",
      "('mean_squared_log_error : ', 0.15833069395117952)\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lddev002/.local/lib/python2.7/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean error', 3.162883488950921e-15)\n",
      "('classifier score : ', 0.9333333333333333)\n",
      "For k =  1 | train set size : 266 | test set size : 30\n",
      "------------------ for k : 1---------------------\n",
      "('classification error : ', 0.06666666666666665)\n",
      "('precision score : ', 0.9472222222222222)\n",
      "('Recall : ', 0.9333333333333333)\n",
      "('F1 score : ', 0.9285242518059856)\n",
      "('Mean Absolute Error : ', 0.23333333333333334)\n",
      "('mean_squared_log_error : ', 0.11432930330995698)\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lddev002/.local/lib/python2.7/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean error', 3.166222505566335e-15)\n",
      "('classifier score : ', 0.8333333333333334)\n",
      "For k =  2 | train set size : 266 | test set size : 30\n",
      "------------------ for k : 2---------------------\n",
      "('classification error : ', 0.16666666666666663)\n",
      "('precision score : ', 0.8125)\n",
      "('Recall : ', 0.8333333333333334)\n",
      "('F1 score : ', 0.8301489016659295)\n",
      "('Mean Absolute Error : ', 0.5666666666666667)\n",
      "('mean_squared_log_error : ', 0.32879312015415185)\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lddev002/.local/lib/python2.7/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean error', 3.167892013874042e-15)\n",
      "('classifier score : ', 0.8666666666666667)\n",
      "For k =  3 | train set size : 266 | test set size : 30\n",
      "------------------ for k : 3---------------------\n",
      "('classification error : ', 0.1333333333333333)\n",
      "('precision score : ', 0.8500000000000001)\n",
      "('Recall : ', 0.8666666666666667)\n",
      "('F1 score : ', 0.8646464646464646)\n",
      "('Mean Absolute Error : ', 0.43333333333333335)\n",
      "('mean_squared_log_error : ', 0.24245010702147737)\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lddev002/.local/lib/python2.7/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean error', 3.1620487347970675e-15)\n",
      "('classifier score : ', 0.8)\n",
      "For k =  4 | train set size : 266 | test set size : 30\n",
      "------------------ for k : 4---------------------\n",
      "('classification error : ', 0.19999999999999996)\n",
      "('precision score : ', 0.780952380952381)\n",
      "('Recall : ', 0.8)\n",
      "('F1 score : ', 0.80030959752322)\n",
      "('Mean Absolute Error : ', 0.4)\n",
      "('mean_squared_log_error : ', 0.13936761897380637)\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lddev002/.local/lib/python2.7/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean error', 3.165387751412482e-15)\n",
      "('classifier score : ', 0.8333333333333334)\n",
      "For k =  5 | train set size : 266 | test set size : 30\n",
      "------------------ for k : 5---------------------\n",
      "('classification error : ', 0.16666666666666663)\n",
      "('precision score : ', 0.875)\n",
      "('Recall : ', 0.8333333333333334)\n",
      "('F1 score : ', 0.8490497076023391)\n",
      "('Mean Absolute Error : ', 0.36666666666666664)\n",
      "('mean_squared_log_error : ', 0.19550074186682173)\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lddev002/.local/lib/python2.7/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean error', 3.1630960855144493e-15)\n",
      "('classifier score : ', 0.7241379310344828)\n",
      "For k =  6 | train set size : 267 | test set size : 29\n",
      "------------------ for k : 6---------------------\n",
      "('classification error : ', 0.27586206896551724)\n",
      "('precision score : ', 0.7166666666666666)\n",
      "('Recall : ', 0.7241379310344828)\n",
      "('F1 score : ', 0.7203431776934499)\n",
      "('Mean Absolute Error : ', 0.7931034482758621)\n",
      "('mean_squared_log_error : ', 0.4513356007639949)\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lddev002/.local/lib/python2.7/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean error', 3.1630960855144493e-15)\n",
      "('classifier score : ', 0.8275862068965517)\n",
      "For k =  7 | train set size : 267 | test set size : 29\n",
      "------------------ for k : 7---------------------\n",
      "('classification error : ', 0.1724137931034483)\n",
      "('precision score : ', 0.8125)\n",
      "('Recall : ', 0.8275862068965517)\n",
      "('F1 score : ', 0.8184311353095384)\n",
      "('Mean Absolute Error : ', 0.5862068965517241)\n",
      "('mean_squared_log_error : ', 0.30281276738862845)\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lddev002/.local/lib/python2.7/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean error', 3.1630960855144493e-15)\n",
      "('classifier score : ', 0.9310344827586207)\n",
      "For k =  8 | train set size : 267 | test set size : 29\n",
      "------------------ for k : 8---------------------\n",
      "('classification error : ', 0.06896551724137934)\n",
      "('precision score : ', 0.9375)\n",
      "('Recall : ', 0.9310344827586207)\n",
      "('F1 score : ', 0.929064039408867)\n",
      "('Mean Absolute Error : ', 0.20689655172413793)\n",
      "('mean_squared_log_error : ', 0.057902669332308594)\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lddev002/.local/lib/python2.7/site-packages/ipykernel_launcher.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean error', 3.163927713248251e-15)\n",
      "('classifier score : ', 0.7931034482758621)\n",
      "For k =  9 | train set size : 267 | test set size : 29\n",
      "------------------ for k : 9---------------------\n",
      "('classification error : ', 0.2068965517241379)\n",
      "('precision score : ', 0.7888888888888889)\n",
      "('Recall : ', 0.7931034482758621)\n",
      "('F1 score : ', 0.7915360501567398)\n",
      "('Mean Absolute Error : ', 0.6551724137931034)\n",
      "('mean_squared_log_error : ', 0.23407703174388306)\n",
      "--------------------------------------------------------\n",
      "Overall score\n",
      "Accuracy: 0.84 (+/- 0.12)\n",
      "('accuracy : ', 0.840919540229885)\n",
      "('classification error : ', 0.15908045977011492)\n",
      "('precision score : ', 0.8404563492063494)\n",
      "('Recall : ', 0.840919540229885)\n",
      "('F1 score : ', 0.8398141812489255)\n",
      "('Train_error Log_loss: ', 3.1641368707497223e-15)\n",
      "('Test_error Log_loss : ', 1.023159941399513)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(10, shuffle=True,random_state = 42)\n",
    "\n",
    "accuracy_list = []\n",
    "classification_error = []\n",
    "recall = []\n",
    "precision_score = []\n",
    "f1_score =[]\n",
    "mean_abs_error = []\n",
    "mean_squ_log_error = []\n",
    "\n",
    "\n",
    "y_true = []\n",
    "y_score = []\n",
    "y_pred = []\n",
    "y_prob = []\n",
    "train_error = []\n",
    "test_error = []\n",
    "x_test_from_fold = []\n",
    "\n",
    "\n",
    "#clf = RandomForestClassifier().set_params(bootstrap=False,max_depth=50,max_features='auto',min_samples_leaf=1,\n",
    "#                                      min_samples_split=2,n_estimators=1000)\n",
    "\n",
    "clf = KNeighborsClassifier().set_params(n_neighbors = 9,n_jobs= -1,\n",
    "                         weights = 'distance',leaf_size= 1,\n",
    "                        algorithm = 'auto')\n",
    "\n",
    "# Random Forest\n",
    "#clf = rf_random.best_estimator_\n",
    "\n",
    "# SVM\n",
    "#clf = svm.SVC(probability=True).set_params(kernel = clf2.best_estimator_.kernel, C= clf2.best_estimator_.C, \n",
    "#                 gamma = clf2.best_estimator_.gamma)\n",
    "\n",
    "#KNN\n",
    "#clf = KNeighborsClassifier().set_params(n_neighbors = 6,n_jobs= -1,\n",
    "#                          weights = 'distance',leaf_size= 1,\n",
    "#                          algorithm = 'auto')\n",
    "\n",
    "\n",
    "for k, (train, test) in enumerate(kf.split(X, Y)):\n",
    "        \n",
    "        clf.fit(X[train],Y[train])\n",
    "       \n",
    "        accuracy = clf.score(X[test],Y[test])     \n",
    "        prediction = clf.predict(X[test])\n",
    "        probability = clf.predict_proba(X[test]) \n",
    "        probability_train = clf.predict_proba(X[train]) \n",
    "        accuracy_list.append(accuracy)\n",
    "        \n",
    "        #for classification report\n",
    "        y_true.append(Y[test])\n",
    "        y_pred.append(clf.predict(X[test]))\n",
    "        y_prob.append(clf.predict_proba(X[test]))\n",
    "        x_test_from_fold.append(X[test])\n",
    "        print(\"mean error\",log_loss(Y[train], probability_train,labels=[0,1,3,4]))\n",
    "        train_error.append(log_loss(Y[train], probability_train,labels=[0,1,3,4]))\n",
    "        test_error.append(log_loss(Y[test], probability,labels=[0,1,3,4]))\n",
    "       \n",
    "        ###\n",
    "\n",
    "        \n",
    "        classification_error.append(1 - metrics.accuracy_score(Y[test], prediction))\n",
    "        recall.append(metrics.recall_score(Y[test], prediction, average='micro'))\n",
    "        precision_score.append(metrics.precision_score(Y[test], prediction, average='macro'))\n",
    "        f1_score.append(metrics.f1_score(Y[test], prediction, average='weighted'))\n",
    "        mean_abs_error.append(mean_absolute_error(Y[test], prediction))\n",
    "        mean_squ_log_error.append(mean_squared_log_error(Y[test], prediction))  \n",
    "        \n",
    "        print(\"classifier score : \",clf.score(X[test],Y[test]))\n",
    "        \n",
    "        print(\"For k =  {} | train set size : {} | test set size : {}\".format(k,X[train].shape[0],X[test].shape[0]))\n",
    "        #classification error\n",
    "        print(\"------------------ for k : {}---------------------\".format(k))\n",
    "        print(\"classification error : \",1 - metrics.accuracy_score(Y[test], prediction))\n",
    "        #evaluation metrices\n",
    "        print(\"precision score : \",metrics.precision_score(Y[test], prediction, average='macro'))\n",
    "        print(\"Recall : \",metrics.recall_score(Y[test], prediction, average='micro'))\n",
    "        print(\"F1 score : \",metrics.f1_score(Y[test], prediction, average='weighted'))\n",
    "        print(\"Mean Absolute Error : \",mean_absolute_error(Y[test], prediction))\n",
    "        print(\"mean_squared_log_error : \",mean_squared_log_error(Y[test], prediction))\n",
    "        print(\"--------------------------------------------------------\")\n",
    "        \n",
    "\n",
    "print(\"Overall score\")\n",
    "#print accuracy % as per cross validation scores\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(accuracy_list),np.std(accuracy_list) * 2))\n",
    "print(\"accuracy : \",np.mean(accuracy_list))\n",
    "print(\"classification error : \",np.mean(classification_error))\n",
    "#evaluation metrices\n",
    "print(\"precision score : \",np.mean(precision_score))\n",
    "print(\"Recall : \",np.mean(recall))\n",
    "print(\"F1 score : \",np.mean(f1_score))\n",
    "print(\"Train_error Log_loss: \",np.mean(train_error))\n",
    "print(\"Test_error Log_loss : \",np.mean(test_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get groundtruth, prediction,probability from 10 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_final = []\n",
    "y_pred_final = []\n",
    "y_prob_final = []\n",
    "x_test_final = []\n",
    "\n",
    "\n",
    "for i,value in enumerate(np.array(y_true)):\n",
    "    for j, val in enumerate(np.array(value)):\n",
    "        y_true_final.append(val)\n",
    "        \n",
    "for k,value1 in enumerate(np.array(y_pred)):\n",
    "    for l, val1 in enumerate(np.array(value1)):\n",
    "        y_pred_final.append(val1)\n",
    "\n",
    "for m,value2 in enumerate(np.array(y_prob)):\n",
    "    for n, val2 in enumerate(np.array(value2)):\n",
    "        y_prob_final.append(val2)\n",
    "        \n",
    "\n",
    "for o,value3 in enumerate(np.array(x_test_from_fold)):\n",
    "    for p, val3 in enumerate(np.array(value3)):\n",
    "        x_test_final.append(val3)\n",
    "                \n",
    "\n",
    "        \n",
    "y_true_new = np.array(y_true_final)\n",
    "y_pred_new = np.array(y_pred_final)\n",
    "y_prob_new = np.array(y_prob_final)\n",
    "x_test_new = np.array(x_test_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ['Car' : 0, 'Cyclist' : 1, 'Misc' : 2, 'Pedestrian' : 3, 'Person (sitting)' : 4, 'Tram' : 5, \n",
    "#'Truck' : 6, 'Van' : 7]\n",
    "misclassified_features_validation = []\n",
    "misclassified_labels_validation = []\n",
    "true_labels_validation = []\n",
    "count1 = 0\n",
    "\n",
    "y_true_new = np.array(y_true_final)\n",
    "y_pred_new = np.array(y_pred_final)\n",
    "y_prob_new = np.array(y_prob_final)\n",
    "\n",
    "print(\"Confusion matrix [Validation data]:\\n\\n%s\\n\\n\" % metrics.confusion_matrix(y_true_new, y_pred_new))\n",
    "\n",
    "#classification report\n",
    "expected = y_true_new\n",
    "predicted = y_pred_new\n",
    "probability = y_prob_new\n",
    "\n",
    "\n",
    "for i,value in enumerate(x_test_new):\n",
    "    if(expected[i] != predicted[i]):\n",
    "        #print(\"actual : {} | predicted : {}\".format(Y_test[i],clf.predict(X_test)[i]))\n",
    "        count1 = count1 + 1\n",
    "        misclassified_features_validation.append(x_test_new[i])\n",
    "        misclassified_labels_validation.append(predicted[i])\n",
    "        true_labels_validation.append(expected[i])\n",
    "        \n",
    "print(\"Number of misclassified labels : {}\\n\".format(count1))\n",
    "print(\"Number of correctly classified labels : {}\\n\".format(x_test_new.shape[0] - count1))\n",
    "\n",
    "\n",
    "print(\"Classification report for RF [Validation data]:\\n\\n%s\\n\\n\"\n",
    "      % (metrics.classification_report(expected, predicted)))\n",
    "\n",
    "\n",
    "#hamming loss\n",
    "\n",
    "hl = hamming_loss(expected, predicted)\n",
    "print(\"Hamming loss [Validation data] : {} \\n\".format(hl))\n",
    "\n",
    "\n",
    "# accuracy score\n",
    "print(\"Accuracy score [Validation data] : {}\\n\".format(accuracy_score(expected, predicted)))\n",
    "\n",
    "# log loss\n",
    "\n",
    "print(\"Log Loss [Validation data] : {}\".format(metrics.log_loss(expected,probability)))\n",
    "\n",
    "#train error\n",
    "\n",
    "print(\"Train error [Validation data] : {}\".format(np.mean(np.array(train_error))))\n",
    "\n",
    "#test error\n",
    "\n",
    "print(\"Test error [Validation data] : {}\".format(np.mean(np.array(test_error))))\n",
    "\n",
    "report = pd.DataFrame(list(precision_recall_fscore_support(expected, predicted)),\n",
    "            index=['Precision', 'Recall', 'F1-score', 'Support']).T\n",
    "\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve\n",
    "sns.set(style=\"darkgrid\")\n",
    "lw = 2\n",
    "n_classes = 4\n",
    "\n",
    "y_test = y_true_new\n",
    "y_score = y_prob_new\n",
    "\n",
    "#interger labels to binary labels\n",
    "y_test = label_binarize(y_test, classes=[0,1,3,4])\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "                       \n",
    "                       \n",
    "                       \n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['blue', 'darkorange', 'cornflowerblue','darkgreen','darkblue','violet',\n",
    "               'yellow','cyan'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for RF Unbalanced Data [Without Feature Scaling] - Simple Features')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sns.set(style=\"darkgrid\")\n",
    "f = plt.figure(figsize=(8,6))\n",
    "sizes = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "viz = LearningCurve(\n",
    "    clf, cv=KFold(10,random_state = 42,shuffle=True), train_sizes=sizes,\n",
    "    scoring='f1_weighted', n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and poof the visualizer\n",
    "viz.fit(X, Y)\n",
    "viz.poof()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "f = plt.figure(figsize=(8,6))\n",
    "# Create range of values for parameter\n",
    "param_range = np.arange(1, 2000, 2)\n",
    "\n",
    "# Calculate accuracy on training and test set using range of parameter values\n",
    "train_scores, test_scores = validation_curve(clf, \n",
    "                                             X, \n",
    "                                             Y, \n",
    "                                             param_name=\"n_estimators\", \n",
    "                                             param_range=param_range,\n",
    "                                             cv=KFold(10, random_state = 42, shuffle=True), \n",
    "                                             scoring=\"accuracy\", \n",
    "                                             n_jobs=-1)\n",
    "\n",
    "\n",
    "# Calculate mean and standard deviation for training set scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Calculate mean and standard deviation for test set scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot mean accuracy scores for training and test sets\n",
    "plt.plot(param_range, train_mean, label=\"Training score\", color=\"green\")\n",
    "plt.plot(param_range, test_mean, label=\"Cross-validation score\", color=\"blue\")\n",
    "\n",
    "# Plot accurancy bands for training and test sets\n",
    "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, color=\"lightgreen\")\n",
    "plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, color=\"lightblue\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Validation Curve With RF\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_pd = result3[['height','width','box_volume','l1','l2','l3','eigen_curvature','eigen_entropy','omnivariance','anisotropy','sum_eigen']]\n",
    "y = result3[['class']]\n",
    "\n",
    "\n",
    "feature_to_plot = ['height','width','box_volume','l1','l2','l3','eigen_curvature','eigen_entropy','omnivariance','anisotropy','sum_eigen']\n",
    "\n",
    "visualizer = FeatureCorrelation(method='mutual_info-classification',\n",
    "                                feature_names=feature_to_plot, sort=True)\n",
    "visualizer.fit(X_pd, y, random_state=0)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(9,6))\n",
    "corr = result3[['height','width','box_volume','l1','l2','l3','eigen_curvature','eigen_entropy','omnivariance','anisotropy','sum_eigen']].corr()\n",
    "sns.heatmap(corr, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Trained Pickled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Unbalanced - without scaling\n",
    "# 3. Unbalanced - with scaling\n",
    "\n",
    "# 2. Balanced - without scaling\n",
    "# 4. Balanced - with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export trained_model\n",
    "import cPickle\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = '2_RF_balanced_without_scaling_simple_features.pkl' \n",
    "with open(pkl_filename, 'wb') as file:  \n",
    "    cPickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export scalars\n",
    "\n",
    "scalerfile1 = '3_KNN_scaler_h_all.sav'\n",
    "cPickle.dump(scaler_h, open(scalerfile1, 'wb'))\n",
    "\n",
    "scalerfile2 = '3_KNN_scaler_w_all.sav'\n",
    "cPickle.dump(scaler_w, open(scalerfile2, 'wb'))\n",
    "\n",
    "scalerfile3 = '3_KNN_scaler_v_all.sav'\n",
    "cPickle.dump(scaler_v, open(scalerfile3, 'wb'))\n",
    "\n",
    "\n",
    "scalerfile4 = '3_KNN_scaler_l1_all.sav'\n",
    "cPickle.dump(scaler_l1, open(scalerfile4, 'wb'))\n",
    "\n",
    "scalerfile5 = '3_KNN_scaler_l2_all.sav'\n",
    "cPickle.dump(scaler_l2, open(scalerfile5, 'wb'))\n",
    "\n",
    "scalerfile6 = '3_KNN_scaler_l3_all.sav'\n",
    "cPickle.dump(scaler_l3, open(scalerfile6, 'wb'))\n",
    "\n",
    "\n",
    "scalerfile7 = '3_KNN_scaler_eigen_curve_all.sav'\n",
    "cPickle.dump(scaler_eigen_curve, open(scalerfile7, 'wb'))\n",
    "\n",
    "scalerfile8 = '3_KNN_scaler_eigen_entropy_all.sav'\n",
    "cPickle.dump(scaler_eigen_entropy, open(scalerfile8, 'wb'))\n",
    "\n",
    "scalerfile9 = '3_KNN_scaler_omnivari_all.sav'\n",
    "cPickle.dump(scaler_omnivariance, open(scalerfile9, 'wb'))\n",
    "\n",
    "\n",
    "scalerfile10 = '3_KNN_scaler_anisotr_all.sav'\n",
    "cPickle.dump(scaler_anisotropy, open(scalerfile10, 'wb'))\n",
    "\n",
    "scalerfile11 = '3_KNN_scaler_sum_eigen_all.sav'\n",
    "cPickle.dump(scaler_sum_eigen, open(scalerfile11, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
